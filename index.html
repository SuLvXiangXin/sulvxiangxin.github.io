<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chun Gu</title>

    <meta name="author" content="Chun Gu">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="apple-touch-icon" sizes="180x180" href="images/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="images/favicon/favicon-16x16.png">
    <link rel="manifest" href="images/favicon/site.webmanifest">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <script>
        function fetchZipNeRFStars() {
            var xhr = new XMLHttpRequest();
            xhr.open("GET", "https://api.github.com/repos/SuLvXiangXin/zipnerf-pytorch", true);
            xhr.onload = function () {
                if (xhr.status === 200) {
                    var repo = JSON.parse(xhr.responseText);
                    document.getElementById("github-stars").innerText = "(" + repo.stargazers_count + " starsðŸŒŸ)";
                } else {
                    document.getElementById("github-stars").innerText = "Error fetching stars";
                }
            };
            xhr.send();
        }
        setInterval(fetchZipNeRFStars, 60000);
    </script>
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chun Gu
                </p>
                <p>I'm a first-year Ph.D. student at Fudan University under the supervision of
                <a href="https://lzrobots.github.io/">Prof. Li Zhang</a>.
                </p>
                <p>
                  I'm interested in Computer Vision and Graphics, especially in 3D reconstruction.
                </p>
                <p style="text-align:center">
                  <a href="mailto:cgu19@fudan.edu.cn">Email</a> &nbsp/&nbsp
                  <a href="https://github.com/SuLvXiangXin/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/photo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/photo_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications & Projects</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      
      <td style="padding:20px;width:25%;vertical-align:middle">
        <img src="images/shenlan-sds/shenlan-sds.jpg" alt="clean-usnob" width="160">
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://www.shenlanxueyuan.com/open/course/225">
          <span class="papertitle">Invited talk at Shenlanxueyuan on 3D generation with SDS</span>
        </a>
        <br>
        <strong>Chun Gu</strong>
        <br>
        <a href="https://www.shenlanxueyuan.com/open/course/225">video</a>
        /
        <a href="images/shenlan-sds/shenlan-sds-slides.pdf">slides</a>
        <p></p>
        <p>
          Providing a brief introduction to the progress in 3D generation using Score Distillation Sampling (SDS).
        </p>
      </td>

      <tr onmouseout="tetsplatting_stop()" onmouseover="tetsplatting_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/tetsplatting/pipeline.jpg" alt="clean-usnob" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/fudan-zvg/tet-splatting">
            <span class="papertitle">Tetrahedron Splatting for 3D Generation</span>
          </a>
          <br>
          <strong>Chun Gu</strong>,
          <a href="https://github.com/Alexander0Yang/">Zeyu Yang</a>,
          <a href="https://github.com/mdarhdarz/">Zijie Pan</a>,
          <a href="https://xiatian-zhu.github.io/">Xiatian Zhu</a>,
          <a href="https://lzrobots.github.io/">Li Zhang</a>
          <br>
          <em>arXiv</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2406.01579">arXiv</a>
          /
          <a href="https://github.com/fudan-zvg/tet-splatting">code</a>
          <p></p>
          <p>
            Integrating surface-based volumetric rendering within a structured tetrahedral grid, utilizing tetrahedra for splatting.
          </p>
        </td>
      </tr>

      <tr onmouseout="diffusion2_stop()" onmouseover="diffusion2_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/diffusion2/teaser.jpg" alt="clean-usnob" width="160">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/fudan-zvg/diffusion-square">
            <span class="papertitle">DiffusionÂ²: Dynamic 3D Content Generation via Score Composition of Orthogonal Diffusion Models</span>
          </a>
          <br>
          <a href="https://github.com/Alexander0Yang/">Zeyu Yang*</a>,
          <a href="https://github.com/mdarhdarz/">Zijie Pan*</a>,
          <strong>Chun Gu</strong>,
          <a href="https://lzrobots.github.io/">Li Zhang</a>
          <br>
          <em>arXiv</em>, 2024
          <br>
          <a href="https://arxiv.org/abs/2404.02148">arXiv</a>
          /
          <a href="https://github.com/fudan-zvg/diffusion-square">code</a>
          <p></p>
          <p>
            In this paper, we propose to achieve 4D generation from directly sampling the dense multi-view multi-frame observation of dynamic content by composing the estimated score of pretrained video and multi-view diffusion models that have learned strong prior of dynamic and geometry.
          </p>
        </td>
      </tr>


      <tr onmouseout="pvg_stop()" onmouseover="pvg_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='pvg'><video  width=100% height=100% muted autoplay loop>
          <source src="images/pvg/video.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/pvg/capture.jpg' width="160">
        </div>
        <script type="text/javascript">
          function pvg_start() {
            document.getElementById('pvg').style.opacity = "1";
          }

          function pvg_stop() {
            document.getElementById('pvg').style.opacity = "0";
          }
          pvg_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://fudan-zvg.github.io/PVG/">
          <span class="papertitle">Periodic Vibration Gaussian: Dynamic Urban Scene Reconstruction and Real-time Rendering</span>
        </a>
        <br>
        <a href="https://github.com/Fumore">Yurui Chen*</a>,
        <strong>Chun Gu*</strong>,
        <a href="https://github.com/selfspin">Junzhe Jiang</a>,
        <a href="https://xiatian-zhu.github.io/">Xiatian Zhu</a>,
        <a href="https://lzrobots.github.io/">Li Zhang</a>
        <br>
        <em>arXiv</em>, 2023
        <br>
        <a href="https://arxiv.org/abs/2311.18561">arXiv</a>
        /
        <a href="https://fudan-zvg.github.io/PVG/">project page</a>
        /
        <a href="https://github.com/fudan-zvg/PVG">code</a>
        <p></p>
        <p>
         A unified representation model for large-scale dynamic urban scene reconstruction.
        </p>
      </td>
    </tr>


      <tr onmouseout="r3dg_stop()" onmouseover="r3dg_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='relightable_3dgs'><video  width=100% height=100% muted autoplay loop>
          <source src="images/relightable_3DGS/pbr_light.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/relightable_3DGS/capture.jpg' width="160">
        </div>
        <script type="text/javascript">
          function r3dg_start() {
            document.getElementById('relightable_3dgs').style.opacity = "1";
          }

          function r3dg_stop() {
            document.getElementById('relightable_3dgs').style.opacity = "0";
          }
          r3dg_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://nju-3dv.github.io/projects/Relightable3DGaussian/">
          <span class="papertitle">Relightable 3D Gaussian: Real-time Point Cloud Relighting with BRDF Decomposition and Ray Tracing</span>
        </a>
        <br>
        <a href="http://ygaojiany.github.io/">Jian Gao*</a>,
        <strong>Chun Gu*</strong>,
        <a href="https://scholar.google.com/citations?user=VhhHLhIAAAAJ&hl=en">Youtian Lin</a>,
        <a href="http://zhuhao.cc/home/">Hao Zhu</a>,
        <a href="https://cite.nju.edu.cn/People/Faculty/20190621/i5054.html">Xun Cao</a>,
        <a href="https://lzrobots.github.io/">Li Zhang</a>,
        <a href="https://yoyo000.github.io/">Yao Yao</a>
        <br>
        <em>ECCV</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2311.16043">arXiv</a>
        /
        <a href="https://nju-3dv.github.io/projects/Relightable3DGaussian/">project page</a>
        /
        <a href="https://github.com/NJU-3DV/Relightable3DGaussian">code</a>
        <p></p>
        <p>
         A novel differentiable point-based rendering framework for material and lighting decomposition from multi-view images, enabling editing, ray-tracing, and real-time relighting of the 3D point cloud.
        </p>
      </td>
    </tr>


      <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/zipnerf/video.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/zipnerf/capture.jpg' width="160">
          </div>
          <script type="text/javascript">
            function zipnerf_start() {
              document.getElementById('zipnerf_image').style.opacity = "1";
            }

            function zipnerf_stop() {
              document.getElementById('zipnerf_image').style.opacity = "0";
            }
            zipnerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/SuLvXiangXin/zipnerf-pytorch">
          <span id="github-stars">Loading stars...</span>
            <span class="papertitle">Unofficial implementation of "Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields"</span>
          </a>
            <script>fetchZipNeRFStars();</script>
          <br>
          <strong>Chun Gu</strong>
          <br>
          <a href="https://github.com/SuLvXiangXin/zipnerf-pytorch">code</a>
          <p></p>
          <p>An unofficial pytorch implementation of  <a href="https://arxiv.org/abs/2304.06706">"Zip-NeRF: Anti-Aliased Grid-Based Neural
          Radiance Fields"</a> based on <a href="https://github.com/google-research/multinerf">multinerf</a>.
          </p>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="images/DT-NeRF/depth.jpg" alt="clean-usnob" width="160" height="160">
        </td>
        <td width="75%" valign="middle">
          <a href="https://arxiv.org/abs/2303.09952">
            <span class="papertitle">Single-view Neural Radiance Fields with Depth Teacher</span>
          </a>
          <br>
            <a href="https://github.com/Fumore">Yurui Chen</a>,
            <strong>Chun Gu</strong>,
            <a href="http://feihuzhang.com/">Feihu Zhang</a>,
            <a href="https://lzrobots.github.io/">Li Zhang</a>,
          <br>
          <em>ICLR workshop 2023</em>
          <br>
          <a href="https://arxiv.org/abs/2303.09952">arXiv</a>
          <p>
        Combining the (coarse) planar rendering and the (fine) volume rendering to achieve higher rendering
          quality and better generalizations. A depth teacher net that predicts dense
          pseudo depth maps is used to supervise the joint rendering mechanism and boost the learning of
          consistent 3D geometry.
        </p>
        </td>
      </tr>

          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  The website template was borrowed from <a href="https://jonbarron.info/">Jon Barron</a>.

                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
